[TOC]

# 第五章 服务器端的局域网中有什么玄机

## 5.1 web服务器的部署地点

### 5.1.1 在公司部署web服务器

最简单的方法就是服务器部署在公司网络中，并且可以直接从互联网访问。这种情况下，网络包经过最近的POP中的路由器，接入网以及服务器路由器之后，就直接到达了服务器。但目前IP地址不足，这样配置需要为公司网络中的所有设备分配公有地址。

另一个不采用这种方法的原因是安全问题，这样任何来自互联网的包都可以进入服务器，会引发安全问题，所以要加上防火墙。

防火墙先对包进行检查，只转发允许通过的包。

### 5.1.2 将web服务器部署在数据中心

可以把服务器 放在网络运营商等管理的数据中心里，或者直接租用运营商提供的服务器。

数据中心是与运营商核心部分NOC直接连接的，或者是与运营商之间的枢纽IX连接，因此部署在这里的服务器可以获得很高的访问速度。而且数据中心一般安全性更高。

如果web服务器部署在数据中心，那么网络包会从互联网的核心部分直接进入数据中心，然后到达服务器。如果数据中心有防火墙，则网络包会先接受防火墙的检查，然后到达服务器

## 5.2 防火墙的结构和原理

### 5.2.1 主流的包过滤方式

防火墙的基本模式：只允许发送到特定服务器中特定应用程序的包通过，然后屏蔽其他的包。

最主流的是包过滤方式。防火墙可以分为包过滤，应用层网关，电路层网关等几种方式。

### 5.2.2 如何设置包过滤规则

网络包的头部含有很多用于控制通信操作的控制信息，可以通过检查这些信息来进行过滤。

假设我们希望允许从互联网访问web服务器，但是禁止web服务器访问互联网，应该怎样设置包过滤规则呢？

通过接收方和发送方的IP地址，我们可以判断包的起点和终点。我们可以**设置允许起点为任意，终点为web服务器IP地址的包通过**。这样一来，从互联网发往web服务器的包就可以通过防火墙了，但这样还是无法访问，因为收到包之后，web服务器需要通过确认应答机制通知发送方数据已经正常收到。这需要web服务器向互联网发送包。这样我们可以**允许起点为web服务器地址的包通过**。

### 5.2.3 通过端口号限定应用程序

按照前面的设置，很容易出现问题，因为任何互联网和web服务器之间的包都可以通过。

假如web服务器上有一个文件服务器程序，那么就有可能发生文件数据泄露。

最好的办法就是 阻止除了必需服务（也就是本例中的web服务）以外所有应用程序的包。

当我们要限定某个应用程序的时候，可以在判断条件中加上TCP头部或者UDP头部中的端口号，web服务器的端口号为80.

### 5.2.4 通过控制位判断连接方向

TCP在连接操作的时候需要发送三个包，其中第一个包的TCP控制位中SYN为1，而ACK为0。其他的包这些值都不同，因此我们可以过滤掉建立连接的第一个包，如果这个包是从web服务器发向互联网的，我们阻止之后，TCP连接操作失败，就阻止了web服务器对互联网的访问。注意的是，我们过滤的是SYN为1且ACK为0的网络包并且是由web服务器发送的网络包，这样可以阻止web服务器对互联网的访问，但是不会阻止从互联网访问web服务器。

通过接收方IP地址，发送方IP地址，接收方端口号，发送方端口号，TCP控制位这些条件，我们可以判断出通信的起点和终点，应用程序的种类以及访问的方向，从而对包进行过滤。

当然存在无法将希望允许通过和阻止的访问完全区分开的情况，比如对DNS服务器的访问，使用的是UDP协议，没有连接操作，无法通过控制位来判断方向。对所有使用UDP协议的应用程序都是这个样。

### 5.2.5 从公司内网访问公开区域的规则

为了让公司内网与公开区域之间的网络包自由流动，我们可以将接收方为公开区域的网络包设置成全部允许通过，并且还需要限定发送方的ip。

### 5.2.6 从外部无法访问公司内网

防火墙不仅可以允许或者阻止网络包的通过，还具备地址转换的功能。也就是说，互联网和公司内网的包需要进行地址转换才能传输，因此必须要进行相关的设置。

具体来说就是和包过滤一样，以起点和终点作为条件，根据需要设置是否需要进行地址转换。私有地址和公有地址之间的对应关系，以及端口号的对应关系都是自动管理的，因此只需要设置是否允许地址转换就可以了。

### 5.2.7 通过防火墙

防火墙设置了各种规格，阻止很多网络包进入。被丢弃的网络包会被记录，其中含有非法入侵的痕迹，分析可以了解入侵者使用的手段，从而帮助我们更好的防范非法入侵。

包过滤并不是防火墙专用的一种特殊机制，而是应该看成在路由器的包转发功能基础上附加的一种功能。

### 5.2.8 防火墙无法抵御的攻击

防火墙可以根据包的起点和终点来判断是否允许其通过，但仅凭这些是不能筛选出所有有风险的包。

问题的根源在于web服务器程序的bug。

## 5.3 通过将请求平均分配给多台服务器来平衡负载

### 5.3.1 性能不足时需要负载均衡

当服务器访问量上升，高速线路会传输大量的网络包，会导致服务器的性能跟不上，尤其是通过CGI程序动态生成数据的时候，对服务器的负担更加严重。

使用多台服务器来分担负载的方法十分有效，这种架构统称为分布式架构。

假设我们有三台服务器来进行分担负载，那么每一台服务器的工作量都是原来的三分之一。必须有一个机制把服务器的请求分配到每台服务器上。最简单的一种方法是通过DNS服务器来分配，采用轮询的方式，依次循环的返回所记录的web服务器的ip地址。轮询可能出现一种问题是，使用CGI动态生成数据的过程中，有些操作需要跨越多个页面，这期间如果访问的服务器发生变化，这个操作可能无法继续。

### 5.3.2 使用负载均衡器分配访问

避免出现前面的问题，使用一个叫负载均衡器的东西，首先要把负载均衡器的ip地址取代web服务器的ip地址并注册到DNS服务器上，把所有发送到web服务器的网络包都发往负载均衡器，然后让负载均衡器来分配，重点就是如何分配？

负载均衡器可以定期采集web服务器的CPU，内存使用率，并根据这些数据判断服务器的负载状况，也可以向web服务器发送测试包，根据响应时间来判断负载状况。还有一种方案是根据事先设置好的服务器性能指数，按比例来分配请求。

HTTP访问都是相互独立的，无法判断和之前的请求是否相关。

可以在发送表单数据的时候在里面加上用来表示关联的信息，或者是对HTTP规格进行扩展，在HTTP头部字段中加上用来判断相关性的信息，这样负载均衡器就可以通过这些信息作出判断。

## 5.4 使用缓存服务器分担负载

### 5.4.1 如何使用缓存服务器

除了使用多台功能相同的web服务器分担负载之外，还有另外一种方法，就是将整个系统按照功能分成不同的服务器。缓存服务器就是一种按功能来分担负载的方法。

缓存服务器是一台通过代理机制对数据进行缓存的服务器。代理介于web服务器和客户端之间，具有对web服务器访问进行中转的功能。当进行中转的时候，它可以将web服务器返回的数据保存在磁盘中，并可以代替web服务器将磁盘中的数据返回给客户端。这种保存的数据称为缓存。

缓存并不是永久可用的。

### 5.4.2 缓存服务器通过更新时间管理内容

缓存服务器和负载均衡服务器一样，需要代替web服务器被注册到DNS服务器中，然后客户端会向缓存服务器发送HTTP请求，缓存服务器接收消息操作和web服务器相同，然后就会查看请求的数据是否在缓存中。

如果没有在缓存中，缓存服务器会在HTTP头部字段中添加一个via字段，表示这个消息经过缓存服务器转发，然后将消息转发给web服务器。会根据请求消息的URL来判断要转发给哪一个服务器。缓存服务器会在响应消息中加上via字段，表示这个消息是经过缓存服务器进行中转的，然后缓存服务器会以web服务器的身份向客户端返回响应消息。同时，缓存服务器会将响应消息保存到缓存中，并记录保存时间。

这种在客户端和web服务器之间充当中间人的方式就是代理的基本原理。

如果在缓存中，缓存服务器会添加一个`If-modified-Since`字段并将请求转发给web服务器，询问web服务器用户请求的数据是否已经发生变化，当web服务器上的数据发生变化的时候，后面的过程和没有命中缓存的情况是一样的。web服务器会返回最新版本的数据，然后缓存服务器加上via字段发送给客户端，同时将数据保存在缓存中。

### 5.4.3 最原始的代理-正向代理

缓存服务器是放在服务器端一侧，实际上缓存服务器最早使用的代理机制是放在客户端一侧的，被称为正向代理（forwa proxy）

防火墙的目的是防止来自互联网的非法入侵，而要达到这个目地，最可靠的方法就是阻止互联网和公司内网之间的所有包，不过公司内部的员工也就无法访问外网，代理可以让必要的包通过，它会先接收来自客户端的请求消息，然后再转发到互联网中，这样就可以实现只允许要的包通过了。

由于代理在转发过程中可以查看请求的内容，所以可以根据内容来判断是否允许访问。

使用正向代理的时候，一般需要在浏览器的设置窗口中的代理服务器一栏填写正向代理的IP地址，浏览器发送请求消息时也会发生一定变化，有正向代理的时候，浏览器会在请求的URL字段填写完整的`http://`网址。

正向代理在转发的时候也有不同，正向代理的时候URL为完整的网址，可以根据网址来转发，不需要像服务器端的缓存服务器一样事先设置好转发目标web服务器。

### 5.4.4 正向代理的改良版

正向代理需要在浏览器中设置，可以把请求消息中URL的目录名称和web服务器关联，和缓存服务器差不多，这种方式称为反向代理。

### 5.4.5 透明代理

查看网络包IP头部中的IP地址，也可以知道用户要访问哪一个服务器，这种方法称为透明代理。

这种方式也可以转发一般的请求消息，

## 5.5 内容分发服务

### 5.5.1 利用内容分发服务分担负载

缓存服务器部署在服务器端还是客户端向效果是有差别的，当缓存服务器放在服务器端的时候，可以减轻web服务器的负载，但是无法减少互联网中的流量。互联网中存在一些拥塞点，部署在客户端处的缓存服务器可以减少这一部分影响，但是部署在客户端的缓存服务器是归客户端的网络运营管理者所有。

web服务器运营者可以和网络运营商签约，将自己控制的缓存服务器放在客户端的运营商处。

一些专门从事相关服务的厂商来部署缓存服务器，并租借给web服务器运营者，这种服务器称为内容分发服务。提供这种服务的厂商称为CDSP，他们会与主要的供应商签约，部署缓存服务器，另一方面会与web服务器运营者签约，使CDSP的缓存服务器配合web服务器工作。当用户访问web服务器的时候，实际上就是在访问CDSP的缓存服务器。

缓存服务器可以缓存多个网站的数据，因此CDSP的缓存服务器可以提供给多个web服务器运营者共享。



### 5.5.2 如何找到最近的缓存服务器

如何在众多缓存服务器中找到距离客户端最近的一个？

第一个方法是像负载均衡一样用DNS服务器来分配访问，对DNS服务器返回ip地址的时候进行一些加工，使其能够返回距离客户端最近的缓存服务器的ip地址。

那么如何判断距离远近呢？

首先从缓存服务器处的路由器收集路由信息，将路由表集中到DNS服务器上。

DNS服务器根据路由表查询从本机到DNS查询消息的发送方，也就是客户端的DNS服务器的路由信息。依次查询所有路由器的路由表I之后，就可以比较出。哪一台服务器距离客户端DNS服务器最近。

提供路由表的路由器位于缓存服务器的位置，而客户端DNS服务器也应该和客户端在同一位置。

### 5.5.3 通过重定向服务分配访问目标

另一个让客户端访问最近的缓存服务器的方法。HTTP中很多头部字段，其中有一个叫做Location的字段。当web服务器数据转移到其他服务器时，可以使用这一个字段，引导客户端访问另一台服务器，这种操作叫做重定向。

首先需要将重定向服务器注册到DNS服务器上，这样客户端会将HTTP请求消息发送到重定向服务器上。重定向服务器和刚才DNS服务器中一样，收集了来自各个路由器的路由信息，并根据这些信息找到最近的缓存服务器，将缓存服务器的地址放在Location字段中返回响应。

这种方式增加了HTTP消息交互次数，但是距离估算更加准确。

重定向服务器也可以返回一个通过网络包往返时间估算到缓存服务器的距离的脚本，通过在客户端运行脚本来寻找最优的缓存服务器。这个脚本可以向不同的缓存服务器发送测试包并计算往返时间，然后将请求发送到往返时间最短的一台缓存服务器。

### 5.5.4 缓存的更新方法会影响性能

有一种方法让web服务器在原始数据发生更新的时候立即通知缓存服务器，是的缓存服务器上的数据一直保存最新状态，这样就不需要每次确认原始数据是否发生变化，内容分发服务采用的缓存服务器就具备这种功能。

还有一种是动态页面是有CGI程序生成的动态页面，是不能保存在缓存服务器上的，可以只保存静态的部分。